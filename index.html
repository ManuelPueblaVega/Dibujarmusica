<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dibujar con Sonido</title>
    <!-- Tailwind CSS CDN para un diseño limpio y adaptable -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Incluir la fuente Inter desde Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
    <!-- Tone.js CDN para la generación de audio -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.49/Tone.js"></script>
    <!-- TensorFlow.js y Handpose para la detección de manos -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.13.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose@0.0.1/dist/handpose.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #1a202c; /* Fondo oscuro */
        }
        /* El canvas debe superponerse al video para que se dibuje encima */
        #drawingCanvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 10;
        }
        /* El video debe ajustarse al contenedor */
        #webcam {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 5;
            object-fit: cover;
        }
        #video-container {
            position: relative;
            width: 100%;
            height: 80vh;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 flex flex-col items-center justify-center min-h-screen p-4">

    <!-- Contenedor principal de la aplicación -->
    <div class="max-w-3xl w-full bg-gray-800 rounded-xl shadow-2xl overflow-hidden p-6 flex flex-col items-center">
        <h1 class="text-3xl sm:text-4xl font-bold mb-4 text-center text-blue-400">Dibujar con Sonido</h1>
        <p class="text-gray-400 text-center mb-6">Usa tu cámara y junta el pulgar y el índice para dibujar y crear sonidos.</p>
        
        <!-- Mensaje de carga del modelo -->
        <div id="loadingMessage" class="text-center text-gray-400 mb-4 font-semibold">
            Cargando modelo de detección de manos... Por favor, espera.
        </div>

        <!-- Contenedor de la cámara y el lienzo de dibujo -->
        <div id="video-container" class="relative w-full rounded-lg overflow-hidden shadow-inner flex justify-center items-center">
            <video id="webcam" playsinline autoplay class="w-full h-full rounded-lg border-2 border-gray-700"></video>
            <canvas id="drawingCanvas" class="w-full h-full rounded-lg border-2 border-gray-700"></canvas>
        </div>

        <!-- Botones de control -->
        <div class="flex space-x-4 mt-6">
            <button id="clearButton" class="bg-red-600 hover:bg-red-700 text-white font-bold py-2 px-6 rounded-full shadow-lg transition-all duration-300 transform hover:scale-105">
                Borrar
            </button>
            <button id="guideButton" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-2 px-6 rounded-full shadow-lg transition-all duration-300 transform hover:scale-105">
                Guía
            </button>
        </div>

        <!-- Mensaje de guía o alerta personalizada -->
        <div id="messageBox" class="fixed inset-0 bg-gray-900 bg-opacity-75 hidden items-center justify-center z-50 p-4">
            <div class="bg-gray-800 p-8 rounded-xl shadow-xl max-w-sm text-center">
                <p class="text-lg text-gray-200">
                    Con la cámara activada, junta el pulgar y el índice de tu mano para empezar a dibujar. El sonido cambiará según la velocidad de tu movimiento.
                </p>
                <button id="closeMessage" class="mt-6 bg-blue-500 hover:bg-blue-600 text-white font-bold py-2 px-4 rounded-full transition-all duration-300">
                    Entendido
                </button>
            </div>
        </div>

    </div>

    <script>
        // Esperar a que el DOM esté completamente cargado antes de ejecutar el script
        window.onload = function() {
            // Referencias a los elementos del DOM
            const video = document.getElementById('webcam');
            const canvas = document.getElementById('drawingCanvas');
            const ctx = canvas.getContext('2d');
            const clearButton = document.getElementById('clearButton');
            const guideButton = document.getElementById('guideButton');
            const messageBox = document.getElementById('messageBox');
            const closeMessageButton = document.getElementById('closeMessage');
            const loadingMessage = document.getElementById('loadingMessage');

            let model;
            let isDrawing = false;
            let lastX = 0;
            let lastY = 0;
            let lastTime = Date.now();

            // Configuración del sintetizador de Tone.js
            // Usamos un PolySynth para evitar que las notas se corten bruscamente
            const synth = new Tone.PolySynth(Tone.Synth, {
                oscillator: { type: "sine" },
                envelope: {
                    attack: 0.01,
                    decay: 0.1,
                    sustain: 0.5,
                    release: 0.5,
                }
            }).toDestination();
            
            // Variable para almacenar la frecuencia actual para el PolySynth
            let currentFrequency = 0;
            
            // Función para redimensionar el canvas y el video para que coincidan
            function resizeElements() {
                const videoContainer = document.getElementById('video-container');
                const { width, height } = videoContainer.getBoundingClientRect();
                
                // Asegurar que el canvas y el video tengan las mismas dimensiones que su contenedor
                canvas.width = width;
                canvas.height = height;
                video.width = width;
                video.height = height;

                // Reiniciar el estilo del contexto después de redimensionar
                ctx.lineWidth = 4;
                ctx.lineCap = 'round';
                ctx.strokeStyle = '#4A90E2'; // Color de línea azul vibrante
            }

            // Función de ayuda para mapear las coordenadas del video al canvas con efecto de espejo
            function mapToCanvas(x, y) {
                const videoWidth = video.videoWidth;
                const videoHeight = video.videoHeight;
                const canvasWidth = canvas.width;
                const canvasHeight = canvas.height;
                
                // Mapear y revertir el eje X para el efecto de espejo
                const mappedX = (1 - (x / videoWidth)) * canvasWidth;
                const mappedY = (y / videoHeight) * canvasHeight;
                
                return { x: mappedX, y: mappedY };
            }
            
            // Iniciar la cámara y el modelo
            async function setup() {
                try {
                    // Obtener el stream de la cámara
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    video.srcObject = stream;
                    
                    // Esperar a que el video cargue los metadatos para obtener las dimensiones
                    await new Promise((resolve) => video.onloadedmetadata = resolve);
                    resizeElements();
                    
                    // Comprobar si la librería Handpose se ha cargado antes de intentar usarla
                    const loadHandposeModel = async () => {
                        if (typeof handpose !== 'undefined') {
                            console.log("Cargando modelo de detección de manos...");
                            model = await handpose.load();
                            loadingMessage.style.display = 'none';
                            console.log("Modelo cargado. Inicando detección.");
                            detectHands(); // Iniciar el bucle de detección de manos
                        } else {
                            // Reintentar si la librería aún no está disponible
                            console.log("Handpose no está definido. Reintentando en 1 segundo...");
                            setTimeout(loadHandposeModel, 1000);
                        }
                    };
                    
                    loadHandposeModel();
                } catch (error) {
                    console.error("Error al acceder a la cámara o cargar el modelo:", error);
                    // Actualiza el mensaje de carga para que sea más informativo
                    loadingMessage.innerHTML = `
                        <p class="text-red-400 mb-2 font-semibold">Error: No se pudo acceder a la cámara.</p>
                        <p class="text-gray-400">Asegúrate de haber dado permiso para usar la cámara y recarga la página.</p>
                    `;
                }
            }

            // Detección de manos con el modelo
            async function detectHands() {
                // Previene errores si el video no está listo
                if (video.readyState < 2) {
                    requestAnimationFrame(detectHands);
                    return;
                }

                // Limpiar el canvas en cada fotograma si no estamos dibujando
                if (!isDrawing) {
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                }

                const predictions = await model.estimateHands(video, true);
                
                if (predictions.length > 0) {
                    const hand = predictions[0];
                    const thumbTip = hand.landmarks[4]; // Índice de la punta del pulgar
                    const indexTip = hand.landmarks[8]; // Índice de la punta del índice
                    
                    // Calcular la distancia entre los dos puntos
                    const distance = Math.sqrt(
                        Math.pow(thumbTip[0] - indexTip[0], 2) +
                        Math.pow(thumbTip[1] - indexTip[1], 2)
                    );
                    
                    // Obtener las coordenadas mapeadas del pulgar y el índice
                    const thumbPos = mapToCanvas(thumbTip[0], thumbTip[1]);
                    const indexPos = mapToCanvas(indexTip[0], indexTip[1]);
                    
                    // Visualización de los puntos detectados para ayudar a la depuración
                    ctx.fillStyle = isDrawing ? '#FFFFFF' : '#FFD700'; // Blanco al dibujar, amarillo para los puntos
                    ctx.beginPath();
                    ctx.arc(thumbPos.x, thumbPos.y, 8, 0, 2 * Math.PI); // Pulgar
                    ctx.fill();
                    ctx.beginPath();
                    ctx.arc(indexPos.x, indexPos.y, 8, 0, 2 * Math.PI); // Índice
                    ctx.fill();

                    // Si la distancia es pequeña, considerar que los dedos están juntos
                    const fingersArePinched = distance < 30; // Umbral para "juntar los dedos"
                    
                    if (fingersArePinched) {
                        // Si los dedos se juntan, empezar o continuar el dibujo y el sonido
                        if (!isDrawing) {
                            isDrawing = true;
                            [lastX, lastY] = [thumbPos.x, thumbPos.y];
                            lastTime = Date.now();
                            Tone.start(); // Iniciar Tone.js con el primer gesto de usuario
                            currentFrequency = 200;
                            synth.triggerAttackRelease(currentFrequency, "8n");
                        } else {
                            // Continuar el dibujo y modular el sonido
                            drawFromHand(thumbPos.x, thumbPos.y);
                        }
                    } else {
                        // Si los dedos se separan, detener el dibujo y el sonido si estaban activos
                        if (isDrawing) {
                            stopDrawing();
                        }
                    }
                } else {
                    // Si no se detectan manos, detener el dibujo si estaba activo
                    if (isDrawing) {
                        stopDrawing();
                    }
                }
                
                requestAnimationFrame(detectHands);
            }
            
            // Función para dibujar y modular el sonido basada en la posición de la mano
            function drawFromHand(x, y) {
                const currentTime = Date.now();
                const deltaTime = (currentTime - lastTime) / 1000; // Tiempo en segundos
                
                // Calcular la velocidad del movimiento
                const dx = x - lastX;
                const dy = y - lastY;
                const speed = Math.sqrt(dx * dx + dy * dy) / (deltaTime > 0 ? deltaTime : 1);

                // Mapear la velocidad a la frecuencia del sonido
                const minFreq = 100;
                const maxFreq = 1200;
                const mappedFreq = Math.min(minFreq + (speed * 0.8), maxFreq); // Factor ajustado
                
                // Actualiza la frecuencia solo si hay un cambio significativo para evitar cortes
                if (Math.abs(mappedFreq - currentFrequency) > 5) {
                    currentFrequency = mappedFreq;
                    synth.triggerAttackRelease(currentFrequency, "16n");
                }
                
                // Dibujar la línea
                ctx.beginPath();
                ctx.moveTo(lastX, lastY);
                ctx.lineTo(x, y);
                ctx.stroke();

                // Actualizar las últimas coordenadas y tiempo
                [lastX, lastY] = [x, y];
                lastTime = currentTime;
            }

            // Función para detener el dibujo y el sonido
            function stopDrawing() {
                if (!isDrawing) return;
                isDrawing = false;
                // Detener el sonido de forma más gradual
                synth.triggerRelease();
            }

            // Evento del botón de borrar
            clearButton.addEventListener('click', () => {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            });
            
            // Evento para mostrar la guía
            guideButton.addEventListener('click', () => {
                messageBox.classList.remove('hidden');
                messageBox.classList.add('flex');
            });
            
            // Evento para cerrar la guía
            closeMessageButton.addEventListener('click', () => {
                messageBox.classList.add('hidden');
                messageBox.classList.remove('flex');
            });

            // Llamar a resize al inicio y cuando se redimensiona la ventana
            window.addEventListener('resize', resizeElements);
            resizeElements();
            
            // Iniciar la configuración de la cámara y el modelo
            setup();
        };
    </script>
</body>
</html>
